<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>COLING2025参加報告</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.15/dist/tailwind.min.css" rel="stylesheet">
    <meta name="robots" content="noindex, follow">
</head>

<body class="bg-gray-50 p-5 md:p-10">
    <div class="max-w-5xl mx-auto bg-white rounded-xl shadow-md overflow-hidden p-5 md:p-10">
        <h1 class="text-2xl md:text-3xl font-bold mb-4">COLING2025 in アブダビ で発表しました！</h1>
        <div class="mb-6 md:mb-8">
            <h2 class="text-xl md:text-2xl font-semibold mb-2">はじめに</h2>
            <p> 白松研究室修士2年の橋本です。この度、アブダビで開催されたCOLING2025に参加しましたので、参加報告を行ないます。また、研究に際しては白松先生、C4A研究所の中野さん、研究室の櫻井くん、東京医療保健大学の駒崎先生、北里大学病院の土屋さんには大変お世話になりました。ありがとうございました。
            </p>
        </div>

        <div class="mb-6 md:mb-8">
            <h2 class="text-xl md:text-2xl font-semibold mb-2">学会概要</h2>
            <p> COLING2025は自然言語処理の国際学会で、今年はアブダビで開催されました。例年COLINGは偶数年に隔年で開催されていましたが、同系統の学会（LREC）との兼ね合いで今年から奇数年に開催されるそうです。また、開催時期としても、今年は1月でしたが、例年は5,6月開催だそうです。
                </br> 今回、私は口頭発表を行いました。発表は12分、質疑応答は3分でした。また、発表者自身がポスター発表か口頭発表の選択が可能でした。（ただし、口頭発表の希望者多数の場合はポスターに変更されるのだと思います。）
                </br> 大会HPは<a href="https://coling2025.org/"
                    style="color: blue; text-decoration: underline;">こちら</a>。
                    投稿数は年々増加し、全体で2335件、ロングペーパーは1922件でした。それに伴って採択率は年々下がっており、全体で30.1%、ロングペーパーは31.5%でした。
            </p>
            <h2 class="text-xl md:text-2xl font-semibold mb-2">発表内容</h2>
            <p> 私が発表したタイトルは「A Career Interview Dialogue System using Large Language Model-based Dynamic Slot
                Generation」でした。具体的には、従来のスロットフィリング型対話システムの課題である、情報収集能力と対話の不自然さを解決するために、LLMを用いてスロットを生成させました。また、もう一つの方法として、スロット生成のプロセスにLLMに仮説形成的推論をさせることによって、スロットの生成精度を向上させました。システムの有効性を検証するために、シミュレータを用いた実験を行いました。
                </br> 詳しくは<a href="https://aclanthology.org/2025.coling-main.106/"
                    style="color: blue; text-decoration: underline;">こちら</a>のページから。日本語版は<a
                    href="https://www.jstage.jst.go.jp/article/jsaislud/101/0/101_01/_article/-char/ja/"
                    style="color: blue; text-decoration: underline;">こちら</a>。
            </p>
        </div>

        <div class="mb-6 md:mb-8">
            <h2 class="text-xl md:text-2xl font-semibold mb-2">質疑応答</h2>
            <p> 質疑応答では、対話にスロットを用いる理由についての質問を受けました。ただ、英語を聞き取ることができず、持ち時間を全てその質問に使ってしまいました。スライドの準備にはかなり時間と労力をかけていたにも関わらず、質疑応答での失敗が非常に悔しかったです。
                </br> 私は質疑をどの学会においても録音するようにしているので、後から聞き直し、内容を把握しました。回答としては、「スロットを用いることによって、包括的な情報を集めることが可能、情報を体系的にまとめることが可能、聞き出す内容の管理が可能」の3点から回答すれば良かったと思います。「聞き出す内容の管理が可能」という点については、システムの目的である看護管理者の支援という面からも強調できたと思います。質問者が対話システム関連の発表者だったことから、非常に的確な質問だったかつ、回答ができていれば良いディスカッションができたと思います。
            </p>
        </div>

        <div class="mb-6 md:mb-8">
            <h2 class="text-xl md:text-2xl font-semibold mb-2">学会全体の感想</h2>
            <p> COLINGは自然言語処理系の学会だったこともあり、LLMを用いた研究が多く、「その面から研究できるのか」という刺激を得ることができました。ただ、対話システムに関する研究は多くはなく、対話におけるあるタスクのための研究が多いように感じました。（私の研究もそういった側面はあるとは思いますが、パッケージとしてあるシステムの目的が分かりづらく、対話タスクと目的の関係性が不明に感じました。）また、ここからLLMの発展によって対話システムは大きく発展しているように感じていましたが、実際にはまだまだ部分的なタスクにしか対応する必要があることが分かりました。
                </br> また、「興味深い研究」でも取り上げますが、個人的には「ブラックボックス化しているLLMのバイアスや挙動」を分析するための研究が非常に興味深かったです。
                </br> 最後に、今回は珍しく中東地域での学会だったこともあり、参加に際して様々な面から不安なこともありましたが、結果的には非常に充実した学会となりました。特に、学会主催のSocial
                Excursionは砂漠でのアトラクションがあり、非常に楽しかったです。また、参加者には日本人が多かったため、日本人同士での交流も深まりました。
            </p>
        </div>

        <div class="mb-6 md:mb-8">
            <h2 class="text-xl md:text-2xl font-semibold mb-2">興味深い研究</h2>
            ここでは個人的に興味があった研究を羅列します。
            <p>
                Why Does ChatGPT “Delve” So Much? Exploring the Sources of Lexical Overrepresentation in Large Language
                Models</br>
                Zero-shot Slot Filling in the Age of LLMs for Dialogue Systems</br>
                Is Peer-Reviewing Worth the Effort?
                査読は努力に値するか?</br>
                Biases in Large Language Model-Elicited Text: A Case Study in Natural Language Inference
                大規模言語モデルから得られたテキストにおけるバイアス： 自然言語推論のケーススタディ</br>
                Can Large Language Models Understand You Better? An MBTI Personality Detection Dataset Aligned with
                Population Traits
                大規模言語モデルはあなたをより理解できるか？母集団の特徴に沿ったMBTI性格検出データセット</br>
                Disentangling Preference Representation and Text Generation for Efficient Individual Preference
                Alignment
                効率的な個人の嗜好アライメントのための嗜好表現とテキスト生成の分離</br>
                Intention Analysis Makes LLMs A Good Jailbreak Defender
                意図分析がLLMを優れた脱獄ディフェンダーにする</br>
                How Well Can Large Language Models Reflect? A Human Evaluation of LLM-generated Reflections for
                Motivational Interviewing Dialogues
                大規模言語モデルはどこまで反映できるか？動機づけ面接対話のためにLLMが生成したリフレクションの人間による評価 </br>
            </p>
        </div>
    </div>
</body>

</html>